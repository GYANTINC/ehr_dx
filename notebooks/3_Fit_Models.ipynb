{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ~/.ipython/standard_imports.py\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import itertools\n",
    "import functools\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.model_selection\n",
    "\n",
    "import isajosep_util\n",
    "import isajosep_util.data_frame_plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ultimately, our goal is to build a ML model that predicts the Diagnosis (DX), based on symptoms and other factors. In the project you can demonstrate doing some or all of the following:\n",
    "- Perform exploratory analysis and visualization of data \n",
    "- **Build one or more ML models on the data (this sheet)**\n",
    "- **Select the best model, and report its performance and error analysis (this sheet)**\n",
    "- Perform feature selection to find most salient features\n",
    "- Explore ways to deal with unbalanced data\n",
    "- Try using external ML classifies (e.g. IBM Watson)\n",
    "etc, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_data = pd.read_pickle('/Users/ijoseph/Code/Data/Gyant/final_formatting_all_obs.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = sklearn.preprocessing.LabelEncoder()\n",
    "le_fit = le.fit(formatted_data.DX)\n",
    "le_trans = le_fit.transform(formatted_data.DX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_data['DX_enc'] = le_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ijoseph/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/ijoseph/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "standard_normed = pd.DataFrame(sklearn.preprocessing.StandardScaler().fit_transform(formatted_data.drop(['DX', 'DX_enc'], axis=1)), index=formatted_data.index , columns=formatted_data.drop(['DX', 'DX_enc'], axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_normed['DX_enc'] = formatted_data.DX_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split with seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = sklearn.model_selection.train_test_split(standard_normed, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15916, 2261), (5306, 2261))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning (via CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use some form of Stochastic Gradient Descent (computes gradients on subset of observations to save time but sacrifice accuracy) for speedups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">‘hinge’ gives a linear SVM.\n",
    "\n",
    ">The ‘log’ loss gives logistic regression, a probabilistic classifier. \n",
    "\n",
    ">‘modified_huber’ is another smooth loss that brings tolerance to outliers as well as probability estimates. \n",
    "\n",
    ">‘squared_hinge’ is like hinge but is quadratically penalized. \n",
    "\n",
    ">‘perceptron’ is the linear loss used by the perceptron algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_est = sklearn.linear_model.SGDClassifier(loss='hinge', penalty ='elasticnet', verbose=2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ElasticNet** penalty. Randomized Search $\\alpha$ (overlal penalty)  from $1 \\times 10^{-8}$ to $1 \\times 10^{8}$, `l1_ratio` (relative $L_1$ vs $L_2$ peantly) from 0.1 to 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {'alpha': np.logspace(-8,8), 'l1_ratio': np.linspace(0.1,0.9)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv_svc = sklearn.model_selection.RandomizedSearchCV(estimator=svc_est, param_distributions=param_distributions, n_jobs=3, cv=3, verbose=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  30 out of  30 | elapsed:  2.3min finished\n",
      "/Users/ijoseph/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 59.88, NNZs: 898, Bias: -204.440537, T: 15916, Avg. loss: 8.699071\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 51.31, NNZs: 864, Bias: -195.900410, T: 31832, Avg. loss: 3.625062\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 48.74, NNZs: 860, Bias: -190.944191, T: 47748, Avg. loss: 3.285287\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.34, NNZs: 850, Bias: -187.498074, T: 63664, Avg. loss: 3.088124\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 46.50, NNZs: 853, Bias: -184.836332, T: 79580, Avg. loss: 2.956824\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 56.57, NNZs: 844, Bias: -172.803930, T: 15916, Avg. loss: 7.335086\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 47.06, NNZs: 819, Bias: -165.096411, T: 31832, Avg. loss: 2.900860\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.59, NNZs: 798, Bias: -160.693205, T: 47748, Avg. loss: 2.637630\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42.11, NNZs: 803, Bias: -157.496739, T: 63664, Avg. loss: 2.532757\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.87, NNZs: 788, Bias: -155.118835, T: 79580, Avg. loss: 2.427951\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.48, NNZs: 696, Bias: -233.916561, T: 15916, Avg. loss: 3.955560\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.48, NNZs: 590, Bias: -232.383398, T: 31832, Avg. loss: 1.624043\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.66, NNZs: 536, Bias: -231.449999, T: 47748, Avg. loss: 1.627520\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.11, NNZs: 489, Bias: -230.805457, T: 63664, Avg. loss: 1.641123\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.53, NNZs: 448, Bias: -230.307810, T: 79580, Avg. loss: 1.646208\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 42.11, NNZs: 755, Bias: -237.247385, T: 15916, Avg. loss: 3.900321\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.62, NNZs: 703, Bias: -234.921844, T: 31832, Avg. loss: 1.446678\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 28.33, NNZs: 687, Bias: -233.541722, T: 47748, Avg. loss: 1.442120\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.59, NNZs: 682, Bias: -232.581595, T: 63664, Avg. loss: 1.424952\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 25.62, NNZs: 658, Bias: -231.833613, T: 79580, Avg. loss: 1.430352\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.72, NNZs: 695, Bias: -236.051445, T: 15916, Avg. loss: 3.701969\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.20, NNZs: 556, Bias: -234.899339, T: 31832, Avg. loss: 1.219967\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.08, NNZs: 473, Bias: -234.230113, T: 47748, Avg. loss: 1.234614\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15.44, NNZs: 424, Bias: -233.739604, T: 63664, Avg. loss: 1.237091\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 13.81, NNZs: 384, Bias: -233.366298, T: 79580, Avg. loss: 1.237699\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 38.33, NNZs: 700, Bias: -246.009931, T: 15916, Avg. loss: 3.540989\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 25.29, NNZs: 525, Bias: -245.008342, T: 31832, Avg. loss: 0.895542\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 20.33, NNZs: 456, Bias: -244.455479, T: 47748, Avg. loss: 0.879893\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.07, NNZs: 407, Bias: -244.038119, T: 63664, Avg. loss: 0.880122\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16.62, NNZs: 354, Bias: -243.719621, T: 79580, Avg. loss: 0.863942\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 49.58, NNZs: 844, Bias: -187.663855, T: 15916, Avg. loss: 5.624994\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.84, NNZs: 776, Bias: -182.946669, T: 31832, Avg. loss: 1.967200\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.61, NNZs: 774, Bias: -180.174699, T: 47748, Avg. loss: 1.842843\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 35.11, NNZs: 761, Bias: -178.200194, T: 63664, Avg. loss: 1.774377\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34.38, NNZs: 755, Bias: -176.647256, T: 79580, Avg. loss: 1.736319\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 56.22, NNZs: 900, Bias: -201.487099, T: 15916, Avg. loss: 5.510691\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 46.79, NNZs: 884, Bias: -195.423977, T: 31832, Avg. loss: 2.141960\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.87, NNZs: 871, Bias: -191.858413, T: 47748, Avg. loss: 2.018289\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42.30, NNZs: 873, Bias: -189.377259, T: 63664, Avg. loss: 1.947707\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 41.54, NNZs: 872, Bias: -187.419906, T: 79580, Avg. loss: 1.912097\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 59.56, NNZs: 902, Bias: -193.715135, T: 15916, Avg. loss: 6.807697\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 49.78, NNZs: 899, Bias: -186.342135, T: 31832, Avg. loss: 2.731389\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 46.45, NNZs: 895, Bias: -182.079789, T: 47748, Avg. loss: 2.529830\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44.98, NNZs: 887, Bias: -179.013090, T: 63664, Avg. loss: 2.431240\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 43.71, NNZs: 884, Bias: -176.738200, T: 79580, Avg. loss: 2.335687\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 56.48, NNZs: 815, Bias: -167.690649, T: 15916, Avg. loss: 8.002337\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 44.99, NNZs: 788, Bias: -160.680773, T: 31832, Avg. loss: 2.984633\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.66, NNZs: 781, Bias: -156.709971, T: 47748, Avg. loss: 2.718015\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 38.60, NNZs: 768, Bias: -153.871022, T: 63664, Avg. loss: 2.577930\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37.38, NNZs: 777, Bias: -151.697690, T: 79580, Avg. loss: 2.507554\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 49.35, NNZs: 800, Bias: -183.202032, T: 15916, Avg. loss: 4.282903\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.15, NNZs: 793, Bias: -178.856375, T: 31832, Avg. loss: 1.327094\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 37.02, NNZs: 785, Bias: -176.357160, T: 47748, Avg. loss: 1.230538\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 35.55, NNZs: 787, Bias: -174.587274, T: 63664, Avg. loss: 1.184360\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34.61, NNZs: 786, Bias: -173.237691, T: 79580, Avg. loss: 1.156798\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.53, NNZs: 683, Bias: -233.893312, T: 15916, Avg. loss: 3.499200\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.59, NNZs: 525, Bias: -232.875355, T: 31832, Avg. loss: 0.988257\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.65, NNZs: 459, Bias: -232.282754, T: 47748, Avg. loss: 0.980876\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.25, NNZs: 413, Bias: -231.852057, T: 63664, Avg. loss: 0.992210\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.67, NNZs: 374, Bias: -231.523116, T: 79580, Avg. loss: 0.989723\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 52.68, NNZs: 808, Bias: -193.457667, T: 15916, Avg. loss: 5.923536\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 44.15, NNZs: 787, Bias: -187.097375, T: 31832, Avg. loss: 2.610003\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.17, NNZs: 791, Bias: -183.435849, T: 47748, Avg. loss: 2.447325\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 39.89, NNZs: 780, Bias: -180.807282, T: 63664, Avg. loss: 2.370037\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 39.08, NNZs: 777, Bias: -178.799720, T: 79580, Avg. loss: 2.305132\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 56.41, NNZs: 866, Bias: -192.584819, T: 15916, Avg. loss: 5.614991\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 46.71, NNZs: 862, Bias: -186.265750, T: 31832, Avg. loss: 2.173115\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.66, NNZs: 862, Bias: -182.599731, T: 47748, Avg. loss: 2.050574\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42.16, NNZs: 863, Bias: -180.007235, T: 63664, Avg. loss: 1.953594\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.94, NNZs: 857, Bias: -178.078184, T: 79580, Avg. loss: 1.887042\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 44.10, NNZs: 706, Bias: -233.919047, T: 15916, Avg. loss: 4.116127\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.81, NNZs: 645, Bias: -231.598271, T: 31832, Avg. loss: 1.153051\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.48, NNZs: 618, Bias: -230.253578, T: 47748, Avg. loss: 1.136517\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.92, NNZs: 590, Bias: -229.282637, T: 63664, Avg. loss: 1.120224\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 27.79, NNZs: 571, Bias: -228.554438, T: 79580, Avg. loss: 1.109924\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 41.88, NNZs: 757, Bias: -225.425322, T: 15916, Avg. loss: 4.317822\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 30.68, NNZs: 729, Bias: -223.051708, T: 31832, Avg. loss: 1.572784\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.09, NNZs: 720, Bias: -221.657710, T: 47748, Avg. loss: 1.563562\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.42, NNZs: 703, Bias: -220.657586, T: 63664, Avg. loss: 1.537855\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 24.37, NNZs: 688, Bias: -219.898525, T: 79580, Avg. loss: 1.521166\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 54.67, NNZs: 835, Bias: -195.634685, T: 15916, Avg. loss: 5.073169\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 44.18, NNZs: 788, Bias: -190.969483, T: 31832, Avg. loss: 1.411197\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.98, NNZs: 769, Bias: -188.190458, T: 47748, Avg. loss: 1.337339\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 39.18, NNZs: 758, Bias: -186.272387, T: 63664, Avg. loss: 1.286952\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.28, NNZs: 751, Bias: -184.753133, T: 79580, Avg. loss: 1.275246\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 43.25, NNZs: 718, Bias: -186.508266, T: 15916, Avg. loss: 3.031206\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.97, NNZs: 695, Bias: -183.291724, T: 31832, Avg. loss: 0.898830\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.29, NNZs: 692, Bias: -181.458522, T: 47748, Avg. loss: 0.857567\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 31.32, NNZs: 688, Bias: -180.108792, T: 63664, Avg. loss: 0.851966\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 30.51, NNZs: 679, Bias: -179.109057, T: 79580, Avg. loss: 0.821120\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 37.24, NNZs: 710, Bias: -236.641115, T: 15916, Avg. loss: 3.273571\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.95, NNZs: 514, Bias: -235.865567, T: 31832, Avg. loss: 0.682441\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.00, NNZs: 412, Bias: -235.426787, T: 47748, Avg. loss: 0.676537\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.55, NNZs: 344, Bias: -235.103962, T: 63664, Avg. loss: 0.668650\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.01, NNZs: 299, Bias: -234.860489, T: 79580, Avg. loss: 0.667353\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 54.48, NNZs: 871, Bias: -186.160508, T: 15916, Avg. loss: 6.033678\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 45.64, NNZs: 840, Bias: -179.912880, T: 31832, Avg. loss: 2.143458\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 42.93, NNZs: 834, Bias: -176.230321, T: 47748, Avg. loss: 1.933349\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 41.71, NNZs: 831, Bias: -173.617223, T: 63664, Avg. loss: 1.852447\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.76, NNZs: 841, Bias: -171.653371, T: 79580, Avg. loss: 1.785460\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.40, NNZs: 722, Bias: -236.148961, T: 15916, Avg. loss: 3.389742\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.52, NNZs: 550, Bias: -235.097621, T: 31832, Avg. loss: 0.991145\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.78, NNZs: 477, Bias: -234.476258, T: 47748, Avg. loss: 1.003291\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.34, NNZs: 420, Bias: -234.033110, T: 63664, Avg. loss: 1.005285\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.85, NNZs: 379, Bias: -233.696357, T: 79580, Avg. loss: 1.010421\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.53, NNZs: 670, Bias: -235.916445, T: 15916, Avg. loss: 3.325067\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.87, NNZs: 499, Bias: -234.964442, T: 31832, Avg. loss: 0.842779\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.41, NNZs: 419, Bias: -234.404485, T: 47748, Avg. loss: 0.847953\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.18, NNZs: 370, Bias: -234.001500, T: 63664, Avg. loss: 0.834423\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.88, NNZs: 329, Bias: -233.687670, T: 79580, Avg. loss: 0.826124\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 55.24, NNZs: 885, Bias: -161.647114, T: 15916, Avg. loss: 8.805373\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.84, NNZs: 852, Bias: -154.472971, T: 31832, Avg. loss: 3.198666\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.03, NNZs: 831, Bias: -150.228457, T: 47748, Avg. loss: 2.928439\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 38.11, NNZs: 831, Bias: -147.242953, T: 63664, Avg. loss: 2.761851\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36.80, NNZs: 826, Bias: -144.957617, T: 79580, Avg. loss: 2.680097\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 47.58, NNZs: 790, Bias: -217.983226, T: 15916, Avg. loss: 3.935105\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 37.75, NNZs: 778, Bias: -214.778248, T: 31832, Avg. loss: 1.124626\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.10, NNZs: 771, Bias: -212.838047, T: 47748, Avg. loss: 1.139037\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 33.68, NNZs: 765, Bias: -211.491743, T: 63664, Avg. loss: 1.091413\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 33.03, NNZs: 750, Bias: -210.428924, T: 79580, Avg. loss: 1.094884\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 51.76, NNZs: 846, Bias: -209.892735, T: 15916, Avg. loss: 5.086500\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.17, NNZs: 846, Bias: -205.389372, T: 31832, Avg. loss: 1.666523\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.51, NNZs: 841, Bias: -202.670499, T: 47748, Avg. loss: 1.551374\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 38.33, NNZs: 841, Bias: -200.752485, T: 63664, Avg. loss: 1.516884\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37.31, NNZs: 845, Bias: -199.335925, T: 79580, Avg. loss: 1.470719\n",
      "Total training time: 0.85 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   21.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='elasticnet',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=2, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=3,\n",
       "          param_distributions={'alpha': array([  1.00000e-08,   2.12095e-08,   4.49843e-08,   9.54095e-08,\n",
       "         2.02359e-07,   4.29193e-07,   9.10298e-07,   1.93070e-06,\n",
       "         4.09492e-06,   8.68511e-06,   1.84207e-05,   3.90694e-05,\n",
       "         8.28643e-05,   1.75751e-04,   3.72759e-04,   7.90604e-04,\n",
       "  ...939,\n",
       "        0.78571,  0.80204,  0.81837,  0.83469,  0.85102,  0.86735,\n",
       "        0.88367,  0.9    ])},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_rscv_svc = rscv_svc.fit(X=train.drop('DX_enc', axis=1), y=train.DX_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63112591103292282"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_rscv_svc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0035564803062231283, 'l1_ratio': 0.26326530612244903}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_rscv_svc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0035564803062231283, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.26326530612244903, learning_rate='optimal', loss='hinge',\n",
       "       max_iter=None, n_iter=None, n_iter_no_change=5, n_jobs=None,\n",
       "       penalty='elasticnet', power_t=0.5, random_state=42, shuffle=True,\n",
       "       tol=None, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_rscv_svc.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_est = sklearn.linear_model.SGDClassifier(loss='log', penalty ='elasticnet', verbose=2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {'alpha': np.logspace(-8,8), 'l1_ratio': np.linspace(0.1,0.9)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv_lr = sklearn.model_selection.RandomizedSearchCV(estimator=lr_est, param_distributions=param_distributions, n_jobs=3, cv=3, verbose=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  30 out of  30 | elapsed:  3.1min finished\n",
      "/Users/ijoseph/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 59.65, NNZs: 905, Bias: -190.156164, T: 15916, Avg. loss: 7.718117\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 50.15, NNZs: 866, Bias: -181.921797, T: 31832, Avg. loss: 3.073852\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 47.27, NNZs: 860, Bias: -177.127108, T: 47748, Avg. loss: 2.825486\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45.75, NNZs: 858, Bias: -173.777732, T: 63664, Avg. loss: 2.665398\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 44.74, NNZs: 856, Bias: -171.214844, T: 79580, Avg. loss: 2.544233\n",
      "Total training time: 1.67 seconds.\n",
      "-- Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 55.93, NNZs: 818, Bias: -169.962616, T: 15916, Avg. loss: 7.026185\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 46.77, NNZs: 804, Bias: -162.241155, T: 31832, Avg. loss: 2.759722\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.19, NNZs: 796, Bias: -157.885005, T: 47748, Avg. loss: 2.513449\n",
      "Total training time: 1.07 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 41.63, NNZs: 800, Bias: -154.733250, T: 63664, Avg. loss: 2.406449\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.36, NNZs: 789, Bias: -152.384405, T: 79580, Avg. loss: 2.314720\n",
      "Total training time: 1.76 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 37.25, NNZs: 704, Bias: -228.694634, T: 15916, Avg. loss: 3.769729\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24.00, NNZs: 588, Bias: -227.161471, T: 31832, Avg. loss: 1.556314\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.10, NNZs: 539, Bias: -226.228071, T: 47748, Avg. loss: 1.559994\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.50, NNZs: 494, Bias: -225.583530, T: 63664, Avg. loss: 1.576469\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.89, NNZs: 452, Bias: -225.085882, T: 79580, Avg. loss: 1.583666\n",
      "Total training time: 1.68 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 41.75, NNZs: 748, Bias: -235.626428, T: 15916, Avg. loss: 3.930775\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.21, NNZs: 710, Bias: -233.342839, T: 31832, Avg. loss: 1.411148\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 28.03, NNZs: 695, Bias: -231.964981, T: 47748, Avg. loss: 1.422471\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.28, NNZs: 674, Bias: -231.014599, T: 63664, Avg. loss: 1.403108\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 25.42, NNZs: 649, Bias: -230.260685, T: 79580, Avg. loss: 1.405477\n",
      "Total training time: 1.65 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 37.25, NNZs: 707, Bias: -236.643862, T: 15916, Avg. loss: 3.727937\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.48, NNZs: 566, Bias: -235.491756, T: 31832, Avg. loss: 1.223091\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.26, NNZs: 493, Bias: -234.822527, T: 47748, Avg. loss: 1.235956\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15.56, NNZs: 443, Bias: -234.332019, T: 63664, Avg. loss: 1.238898\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 13.89, NNZs: 395, Bias: -233.958360, T: 79580, Avg. loss: 1.239432\n",
      "Total training time: 1.66 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.85, NNZs: 684, Bias: -234.780648, T: 15916, Avg. loss: 3.283295\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24.38, NNZs: 518, Bias: -233.794942, T: 31832, Avg. loss: 0.847939\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.64, NNZs: 443, Bias: -233.240731, T: 47748, Avg. loss: 0.833330\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.51, NNZs: 381, Bias: -232.823384, T: 63664, Avg. loss: 0.830901\n",
      "Total training time: 1.32 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16.11, NNZs: 343, Bias: -232.508834, T: 79580, Avg. loss: 0.810941\n",
      "Total training time: 1.64 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 49.90, NNZs: 836, Bias: -187.703710, T: 15916, Avg. loss: 5.586312\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.81, NNZs: 772, Bias: -183.033819, T: 31832, Avg. loss: 1.965419\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.51, NNZs: 759, Bias: -180.266629, T: 47748, Avg. loss: 1.843998\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 35.09, NNZs: 753, Bias: -178.273895, T: 63664, Avg. loss: 1.770067\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34.30, NNZs: 744, Bias: -176.725586, T: 79580, Avg. loss: 1.728620\n",
      "Total training time: 1.63 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 55.59, NNZs: 879, Bias: -197.115655, T: 15916, Avg. loss: 5.328204\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 45.96, NNZs: 859, Bias: -191.142930, T: 31832, Avg. loss: 2.073731\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.15, NNZs: 855, Bias: -187.589253, T: 47748, Avg. loss: 1.950626\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 41.56, NNZs: 854, Bias: -185.135764, T: 63664, Avg. loss: 1.862701\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.80, NNZs: 855, Bias: -183.197938, T: 79580, Avg. loss: 1.826982\n",
      "Total training time: 1.83 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 58.98, NNZs: 893, Bias: -195.148232, T: 15916, Avg. loss: 6.760489\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 49.51, NNZs: 890, Bias: -187.770350, T: 31832, Avg. loss: 2.741989\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 46.46, NNZs: 887, Bias: -183.455306, T: 47748, Avg. loss: 2.523412\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45.01, NNZs: 876, Bias: -180.387586, T: 63664, Avg. loss: 2.410798\n",
      "Total training time: 1.45 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 43.83, NNZs: 868, Bias: -178.093162, T: 79580, Avg. loss: 2.316076\n",
      "Total training time: 1.80 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 56.40, NNZs: 853, Bias: -153.251464, T: 15916, Avg. loss: 7.232586\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.76, NNZs: 791, Bias: -146.529200, T: 31832, Avg. loss: 2.582127\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.30, NNZs: 773, Bias: -142.652024, T: 47748, Avg. loss: 2.321979\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 37.10, NNZs: 764, Bias: -139.904577, T: 63664, Avg. loss: 2.186843\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 35.92, NNZs: 766, Bias: -137.759411, T: 79580, Avg. loss: 2.119149\n",
      "Total training time: 1.75 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 51.52, NNZs: 810, Bias: -195.909012, T: 15916, Avg. loss: 4.476084\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.79, NNZs: 785, Bias: -191.464559, T: 31832, Avg. loss: 1.441254\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38.63, NNZs: 783, Bias: -188.892960, T: 47748, Avg. loss: 1.324753\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 37.15, NNZs: 788, Bias: -187.067987, T: 63664, Avg. loss: 1.278440\n",
      "Total training time: 1.44 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36.23, NNZs: 780, Bias: -185.672920, T: 79580, Avg. loss: 1.245304\n",
      "Total training time: 1.78 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.63, NNZs: 715, Bias: -235.619950, T: 15916, Avg. loss: 3.472749\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.67, NNZs: 562, Bias: -234.601994, T: 31832, Avg. loss: 0.987392\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.72, NNZs: 493, Bias: -234.009392, T: 47748, Avg. loss: 0.981450\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.32, NNZs: 438, Bias: -233.578696, T: 63664, Avg. loss: 0.992858\n",
      "Total training time: 1.39 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.74, NNZs: 392, Bias: -233.249715, T: 79580, Avg. loss: 0.990870\n",
      "Total training time: 1.74 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 53.02, NNZs: 833, Bias: -188.624467, T: 15916, Avg. loss: 5.621449\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.84, NNZs: 809, Bias: -182.383888, T: 31832, Avg. loss: 2.464458\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.71, NNZs: 805, Bias: -178.772394, T: 47748, Avg. loss: 2.312516\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 39.40, NNZs: 800, Bias: -176.166152, T: 63664, Avg. loss: 2.241014\n",
      "Total training time: 1.41 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.50, NNZs: 794, Bias: -174.193380, T: 79580, Avg. loss: 2.184094\n",
      "Total training time: 1.76 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 53.44, NNZs: 837, Bias: -184.793216, T: 15916, Avg. loss: 5.447621\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 44.93, NNZs: 840, Bias: -178.491846, T: 31832, Avg. loss: 2.024242\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 42.01, NNZs: 833, Bias: -174.927972, T: 47748, Avg. loss: 1.903229\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 40.65, NNZs: 831, Bias: -172.381372, T: 63664, Avg. loss: 1.808985\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 39.50, NNZs: 834, Bias: -170.491621, T: 79580, Avg. loss: 1.743480\n",
      "Total training time: 1.68 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 40.76, NNZs: 695, Bias: -204.784607, T: 15916, Avg. loss: 3.559782\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 30.94, NNZs: 638, Bias: -202.583338, T: 31832, Avg. loss: 0.989884\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.56, NNZs: 611, Bias: -201.330266, T: 47748, Avg. loss: 0.967686\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.12, NNZs: 580, Bias: -200.404239, T: 63664, Avg. loss: 0.960150\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 24.94, NNZs: 551, Bias: -199.732352, T: 79580, Avg. loss: 0.949376\n",
      "Total training time: 1.66 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 41.78, NNZs: 766, Bias: -231.740257, T: 15916, Avg. loss: 4.274321\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 30.92, NNZs: 738, Bias: -229.336219, T: 31832, Avg. loss: 1.624302\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.25, NNZs: 716, Bias: -227.941865, T: 47748, Avg. loss: 1.603528\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.66, NNZs: 703, Bias: -226.933953, T: 63664, Avg. loss: 1.583476\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 24.55, NNZs: 675, Bias: -226.178433, T: 79580, Avg. loss: 1.563035\n",
      "Total training time: 1.66 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 49.91, NNZs: 781, Bias: -181.744993, T: 15916, Avg. loss: 4.346727\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.80, NNZs: 741, Bias: -177.248851, T: 31832, Avg. loss: 1.256004\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38.18, NNZs: 718, Bias: -174.550489, T: 47748, Avg. loss: 1.187505\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 36.75, NNZs: 716, Bias: -172.683959, T: 63664, Avg. loss: 1.132325\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 35.88, NNZs: 707, Bias: -171.240268, T: 79580, Avg. loss: 1.122316\n",
      "Total training time: 1.71 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 45.11, NNZs: 730, Bias: -190.278110, T: 15916, Avg. loss: 3.155907\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 36.00, NNZs: 704, Bias: -187.017137, T: 31832, Avg. loss: 0.931693\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 33.04, NNZs: 699, Bias: -185.154043, T: 47748, Avg. loss: 0.886476\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 31.91, NNZs: 691, Bias: -183.791822, T: 63664, Avg. loss: 0.881508\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 31.02, NNZs: 686, Bias: -182.783183, T: 79580, Avg. loss: 0.848759\n",
      "Total training time: 1.71 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 37.57, NNZs: 735, Bias: -236.497957, T: 15916, Avg. loss: 3.264670\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24.13, NNZs: 518, Bias: -235.722414, T: 31832, Avg. loss: 0.678926\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.15, NNZs: 423, Bias: -235.283633, T: 47748, Avg. loss: 0.668089\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.66, NNZs: 353, Bias: -234.961299, T: 63664, Avg. loss: 0.660498\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.10, NNZs: 314, Bias: -234.717802, T: 79580, Avg. loss: 0.660541\n",
      "Total training time: 1.71 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 53.05, NNZs: 846, Bias: -180.411148, T: 15916, Avg. loss: 5.796478\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 44.57, NNZs: 829, Bias: -174.230722, T: 31832, Avg. loss: 1.990997\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.91, NNZs: 823, Bias: -170.613506, T: 47748, Avg. loss: 1.793638\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 40.68, NNZs: 820, Bias: -168.050571, T: 63664, Avg. loss: 1.711050\n",
      "Total training time: 1.44 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 39.78, NNZs: 825, Bias: -166.111606, T: 79580, Avg. loss: 1.653053\n",
      "Total training time: 1.81 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 37.18, NNZs: 732, Bias: -236.740261, T: 15916, Avg. loss: 3.434459\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.87, NNZs: 573, Bias: -235.688920, T: 31832, Avg. loss: 1.004400\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.95, NNZs: 500, Bias: -235.067558, T: 47748, Avg. loss: 1.017866\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.41, NNZs: 439, Bias: -234.624410, T: 63664, Avg. loss: 1.018177\n",
      "Total training time: 1.44 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.86, NNZs: 394, Bias: -234.287657, T: 79580, Avg. loss: 1.021540\n",
      "Total training time: 1.78 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.61, NNZs: 717, Bias: -240.232055, T: 15916, Avg. loss: 3.406531\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.92, NNZs: 523, Bias: -239.271181, T: 31832, Avg. loss: 0.868084\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.36, NNZs: 430, Bias: -238.717468, T: 47748, Avg. loss: 0.865793\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.12, NNZs: 381, Bias: -238.314489, T: 63664, Avg. loss: 0.857823\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.81, NNZs: 338, Bias: -238.000662, T: 79580, Avg. loss: 0.849494\n",
      "Total training time: 1.72 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 53.98, NNZs: 878, Bias: -163.038475, T: 15916, Avg. loss: 8.669095\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.23, NNZs: 838, Bias: -155.801422, T: 31832, Avg. loss: 3.194667\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.55, NNZs: 830, Bias: -151.561252, T: 47748, Avg. loss: 2.924269\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 37.79, NNZs: 836, Bias: -148.551026, T: 63664, Avg. loss: 2.758188\n",
      "Total training time: 1.41 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36.56, NNZs: 825, Bias: -146.260049, T: 79580, Avg. loss: 2.673828\n",
      "Total training time: 1.77 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 45.51, NNZs: 766, Bias: -206.004901, T: 15916, Avg. loss: 3.589097\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 36.30, NNZs: 753, Bias: -202.858486, T: 31832, Avg. loss: 1.017408\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 33.76, NNZs: 750, Bias: -200.960952, T: 47748, Avg. loss: 1.020266\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 32.44, NNZs: 746, Bias: -199.639885, T: 63664, Avg. loss: 0.977515\n",
      "Total training time: 1.38 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 31.76, NNZs: 735, Bias: -198.612159, T: 79580, Avg. loss: 0.975724\n",
      "Total training time: 1.72 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 50.11, NNZs: 825, Bias: -207.411644, T: 15916, Avg. loss: 4.883265\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.26, NNZs: 829, Bias: -202.908249, T: 31832, Avg. loss: 1.613320\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38.86, NNZs: 836, Bias: -200.195555, T: 47748, Avg. loss: 1.504922\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 37.73, NNZs: 833, Bias: -198.299784, T: 63664, Avg. loss: 1.469262\n",
      "Total training time: 1.43 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36.80, NNZs: 837, Bias: -196.884005, T: 79580, Avg. loss: 1.418428\n",
      "Total training time: 1.79 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   43.1s finished\n"
     ]
    }
   ],
   "source": [
    "fit_rscv_lr = rscv_lr.fit(X=train.drop('DX_enc', axis=1), y=train.DX_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63024629303845192"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_rscv_lr.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0035564803062231283, 'l1_ratio': 0.26326530612244903}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_rscv_lr.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0035564803062231283, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.26326530612244903, learning_rate='optimal', loss='log',\n",
       "       max_iter=None, n_iter=None, n_iter_no_change=5, n_jobs=None,\n",
       "       penalty='elasticnet', power_t=0.5, random_state=42, shuffle=True,\n",
       "       tol=None, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_rscv_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrainer = sklearn.linear_model.SGDClassifier(loss='hinge', penalty ='elasticnet', verbose=2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain using best params on full training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrainer = retrainer.set_params(**fit_rscv_svc.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ijoseph/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 59.88, NNZs: 898, Bias: -204.440537, T: 15916, Avg. loss: 8.699071\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 51.31, NNZs: 864, Bias: -195.900410, T: 31832, Avg. loss: 3.625062\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 48.74, NNZs: 860, Bias: -190.944191, T: 47748, Avg. loss: 3.285287\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.34, NNZs: 850, Bias: -187.498074, T: 63664, Avg. loss: 3.088124\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 46.50, NNZs: 853, Bias: -184.836332, T: 79580, Avg. loss: 2.956824\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 56.57, NNZs: 844, Bias: -172.803930, T: 15916, Avg. loss: 7.335086\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 47.06, NNZs: 819, Bias: -165.096411, T: 31832, Avg. loss: 2.900860\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.59, NNZs: 798, Bias: -160.693205, T: 47748, Avg. loss: 2.637630\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42.11, NNZs: 803, Bias: -157.496739, T: 63664, Avg. loss: 2.532757\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.87, NNZs: 788, Bias: -155.118835, T: 79580, Avg. loss: 2.427951\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.48, NNZs: 696, Bias: -233.916561, T: 15916, Avg. loss: 3.955560\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.48, NNZs: 590, Bias: -232.383398, T: 31832, Avg. loss: 1.624043\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.66, NNZs: 536, Bias: -231.449999, T: 47748, Avg. loss: 1.627520\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.11, NNZs: 489, Bias: -230.805457, T: 63664, Avg. loss: 1.641123\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.53, NNZs: 448, Bias: -230.307810, T: 79580, Avg. loss: 1.646208\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 42.11, NNZs: 755, Bias: -237.247385, T: 15916, Avg. loss: 3.900321\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.62, NNZs: 703, Bias: -234.921844, T: 31832, Avg. loss: 1.446678\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 28.33, NNZs: 687, Bias: -233.541722, T: 47748, Avg. loss: 1.442120\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.59, NNZs: 682, Bias: -232.581595, T: 63664, Avg. loss: 1.424952\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 25.62, NNZs: 658, Bias: -231.833613, T: 79580, Avg. loss: 1.430352\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.72, NNZs: 695, Bias: -236.051445, T: 15916, Avg. loss: 3.701969\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.20, NNZs: 556, Bias: -234.899339, T: 31832, Avg. loss: 1.219967\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.08, NNZs: 473, Bias: -234.230113, T: 47748, Avg. loss: 1.234614\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15.44, NNZs: 424, Bias: -233.739604, T: 63664, Avg. loss: 1.237091\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 13.81, NNZs: 384, Bias: -233.366298, T: 79580, Avg. loss: 1.237699\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 38.33, NNZs: 700, Bias: -246.009931, T: 15916, Avg. loss: 3.540989\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 25.29, NNZs: 525, Bias: -245.008342, T: 31832, Avg. loss: 0.895542\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 20.33, NNZs: 456, Bias: -244.455479, T: 47748, Avg. loss: 0.879893\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.07, NNZs: 407, Bias: -244.038119, T: 63664, Avg. loss: 0.880122\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16.62, NNZs: 354, Bias: -243.719621, T: 79580, Avg. loss: 0.863942\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 49.58, NNZs: 844, Bias: -187.663855, T: 15916, Avg. loss: 5.624994\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.84, NNZs: 776, Bias: -182.946669, T: 31832, Avg. loss: 1.967200\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.61, NNZs: 774, Bias: -180.174699, T: 47748, Avg. loss: 1.842843\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 35.11, NNZs: 761, Bias: -178.200194, T: 63664, Avg. loss: 1.774377\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34.38, NNZs: 755, Bias: -176.647256, T: 79580, Avg. loss: 1.736319\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 56.22, NNZs: 900, Bias: -201.487099, T: 15916, Avg. loss: 5.510691\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 46.79, NNZs: 884, Bias: -195.423977, T: 31832, Avg. loss: 2.141960\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.87, NNZs: 871, Bias: -191.858413, T: 47748, Avg. loss: 2.018289\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42.30, NNZs: 873, Bias: -189.377259, T: 63664, Avg. loss: 1.947707\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 41.54, NNZs: 872, Bias: -187.419906, T: 79580, Avg. loss: 1.912097\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 59.56, NNZs: 902, Bias: -193.715135, T: 15916, Avg. loss: 6.807697\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 49.78, NNZs: 899, Bias: -186.342135, T: 31832, Avg. loss: 2.731389\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 46.45, NNZs: 895, Bias: -182.079789, T: 47748, Avg. loss: 2.529830\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44.98, NNZs: 887, Bias: -179.013090, T: 63664, Avg. loss: 2.431240\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 43.71, NNZs: 884, Bias: -176.738200, T: 79580, Avg. loss: 2.335687\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 56.48, NNZs: 815, Bias: -167.690649, T: 15916, Avg. loss: 8.002337\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 44.99, NNZs: 788, Bias: -160.680773, T: 31832, Avg. loss: 2.984633\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.66, NNZs: 781, Bias: -156.709971, T: 47748, Avg. loss: 2.718015\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 38.60, NNZs: 768, Bias: -153.871022, T: 63664, Avg. loss: 2.577930\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37.38, NNZs: 777, Bias: -151.697690, T: 79580, Avg. loss: 2.507554\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 49.35, NNZs: 800, Bias: -183.202032, T: 15916, Avg. loss: 4.282903\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.15, NNZs: 793, Bias: -178.856375, T: 31832, Avg. loss: 1.327094\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 37.02, NNZs: 785, Bias: -176.357160, T: 47748, Avg. loss: 1.230538\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 35.55, NNZs: 787, Bias: -174.587274, T: 63664, Avg. loss: 1.184360\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34.61, NNZs: 786, Bias: -173.237691, T: 79580, Avg. loss: 1.156798\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.53, NNZs: 683, Bias: -233.893312, T: 15916, Avg. loss: 3.499200\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.59, NNZs: 525, Bias: -232.875355, T: 31832, Avg. loss: 0.988257\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.65, NNZs: 459, Bias: -232.282754, T: 47748, Avg. loss: 0.980876\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.25, NNZs: 413, Bias: -231.852057, T: 63664, Avg. loss: 0.992210\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.67, NNZs: 374, Bias: -231.523116, T: 79580, Avg. loss: 0.989723\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 52.68, NNZs: 808, Bias: -193.457667, T: 15916, Avg. loss: 5.923536\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 44.15, NNZs: 787, Bias: -187.097375, T: 31832, Avg. loss: 2.610003\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.17, NNZs: 791, Bias: -183.435849, T: 47748, Avg. loss: 2.447325\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 39.89, NNZs: 780, Bias: -180.807282, T: 63664, Avg. loss: 2.370037\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 39.08, NNZs: 777, Bias: -178.799720, T: 79580, Avg. loss: 2.305132\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 56.41, NNZs: 866, Bias: -192.584819, T: 15916, Avg. loss: 5.614991\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 46.71, NNZs: 862, Bias: -186.265750, T: 31832, Avg. loss: 2.173115\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.66, NNZs: 862, Bias: -182.599731, T: 47748, Avg. loss: 2.050574\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42.16, NNZs: 863, Bias: -180.007235, T: 63664, Avg. loss: 1.953594\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.94, NNZs: 857, Bias: -178.078184, T: 79580, Avg. loss: 1.887042\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 44.10, NNZs: 706, Bias: -233.919047, T: 15916, Avg. loss: 4.116127\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.81, NNZs: 645, Bias: -231.598271, T: 31832, Avg. loss: 1.153051\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.48, NNZs: 618, Bias: -230.253578, T: 47748, Avg. loss: 1.136517\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.92, NNZs: 590, Bias: -229.282637, T: 63664, Avg. loss: 1.120224\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 27.79, NNZs: 571, Bias: -228.554438, T: 79580, Avg. loss: 1.109924\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 41.88, NNZs: 757, Bias: -225.425322, T: 15916, Avg. loss: 4.317822\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 30.68, NNZs: 729, Bias: -223.051708, T: 31832, Avg. loss: 1.572784\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.09, NNZs: 720, Bias: -221.657710, T: 47748, Avg. loss: 1.563562\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.42, NNZs: 703, Bias: -220.657586, T: 63664, Avg. loss: 1.537855\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 24.37, NNZs: 688, Bias: -219.898525, T: 79580, Avg. loss: 1.521166\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 54.67, NNZs: 835, Bias: -195.634685, T: 15916, Avg. loss: 5.073169\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 44.18, NNZs: 788, Bias: -190.969483, T: 31832, Avg. loss: 1.411197\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.98, NNZs: 769, Bias: -188.190458, T: 47748, Avg. loss: 1.337339\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 39.18, NNZs: 758, Bias: -186.272387, T: 63664, Avg. loss: 1.286952\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.28, NNZs: 751, Bias: -184.753133, T: 79580, Avg. loss: 1.275246\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 43.25, NNZs: 718, Bias: -186.508266, T: 15916, Avg. loss: 3.031206\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.97, NNZs: 695, Bias: -183.291724, T: 31832, Avg. loss: 0.898830\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.29, NNZs: 692, Bias: -181.458522, T: 47748, Avg. loss: 0.857567\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 31.32, NNZs: 688, Bias: -180.108792, T: 63664, Avg. loss: 0.851966\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 30.51, NNZs: 679, Bias: -179.109057, T: 79580, Avg. loss: 0.821120\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 37.24, NNZs: 710, Bias: -236.641115, T: 15916, Avg. loss: 3.273571\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.95, NNZs: 514, Bias: -235.865567, T: 31832, Avg. loss: 0.682441\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.00, NNZs: 412, Bias: -235.426787, T: 47748, Avg. loss: 0.676537\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.55, NNZs: 344, Bias: -235.103962, T: 63664, Avg. loss: 0.668650\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.01, NNZs: 299, Bias: -234.860489, T: 79580, Avg. loss: 0.667353\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 54.48, NNZs: 871, Bias: -186.160508, T: 15916, Avg. loss: 6.033678\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 45.64, NNZs: 840, Bias: -179.912880, T: 31832, Avg. loss: 2.143458\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 42.93, NNZs: 834, Bias: -176.230321, T: 47748, Avg. loss: 1.933349\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 41.71, NNZs: 831, Bias: -173.617223, T: 63664, Avg. loss: 1.852447\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.76, NNZs: 841, Bias: -171.653371, T: 79580, Avg. loss: 1.785460\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.40, NNZs: 722, Bias: -236.148961, T: 15916, Avg. loss: 3.389742\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.52, NNZs: 550, Bias: -235.097621, T: 31832, Avg. loss: 0.991145\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.78, NNZs: 477, Bias: -234.476258, T: 47748, Avg. loss: 1.003291\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.34, NNZs: 420, Bias: -234.033110, T: 63664, Avg. loss: 1.005285\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.85, NNZs: 379, Bias: -233.696357, T: 79580, Avg. loss: 1.010421\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.53, NNZs: 670, Bias: -235.916445, T: 15916, Avg. loss: 3.325067\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.87, NNZs: 499, Bias: -234.964442, T: 31832, Avg. loss: 0.842779\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.41, NNZs: 419, Bias: -234.404485, T: 47748, Avg. loss: 0.847953\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.18, NNZs: 370, Bias: -234.001500, T: 63664, Avg. loss: 0.834423\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.88, NNZs: 329, Bias: -233.687670, T: 79580, Avg. loss: 0.826124\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 55.24, NNZs: 885, Bias: -161.647114, T: 15916, Avg. loss: 8.805373\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.84, NNZs: 852, Bias: -154.472971, T: 31832, Avg. loss: 3.198666\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.03, NNZs: 831, Bias: -150.228457, T: 47748, Avg. loss: 2.928439\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 38.11, NNZs: 831, Bias: -147.242953, T: 63664, Avg. loss: 2.761851\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36.80, NNZs: 826, Bias: -144.957617, T: 79580, Avg. loss: 2.680097\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 47.58, NNZs: 790, Bias: -217.983226, T: 15916, Avg. loss: 3.935105\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 37.75, NNZs: 778, Bias: -214.778248, T: 31832, Avg. loss: 1.124626\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.10, NNZs: 771, Bias: -212.838047, T: 47748, Avg. loss: 1.139037\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 33.68, NNZs: 765, Bias: -211.491743, T: 63664, Avg. loss: 1.091413\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 33.03, NNZs: 750, Bias: -210.428924, T: 79580, Avg. loss: 1.094884\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 51.76, NNZs: 846, Bias: -209.892735, T: 15916, Avg. loss: 5.086500\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.17, NNZs: 846, Bias: -205.389372, T: 31832, Avg. loss: 1.666523\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.51, NNZs: 841, Bias: -202.670499, T: 47748, Avg. loss: 1.551374\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 38.33, NNZs: 841, Bias: -200.752485, T: 63664, Avg. loss: 1.516884\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37.31, NNZs: 845, Bias: -199.335925, T: 79580, Avg. loss: 1.470719\n",
      "Total training time: 1.24 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   21.1s finished\n"
     ]
    }
   ],
   "source": [
    "retrainer_fit = retrainer.fit(X=train.drop('DX_enc', axis=1), y=train.DX_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset accuracy (correcly-classified observations / total observations): 0.68\n"
     ]
    }
   ],
   "source": [
    "print(\"Subset accuracy (correcly-classified observations / total observations): {:.2f}\".format(retrainer_fit.score(X=train.drop('DX_enc', axis=1), y=train.DX_enc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset accuracy score. Not bad. \n",
    "> [subset accuracy](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html): the set of labels predicted for a sample must exactly match the corresponding set of labels in y_true."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
