{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ~/.ipython/standard_imports.py\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import itertools\n",
    "import functools\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.model_selection\n",
    "\n",
    "import isajosep_util\n",
    "import isajosep_util.data_frame_plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ultimately, our goal is to build a ML model that predicts the Diagnosis (DX), based on symptoms and other factors. In the project you can demonstrate doing some or all of the following:\n",
    "- Perform exploratory analysis and visualization of data \n",
    "- **Build one or more ML models on the data (this sheet)**\n",
    "- **Select the best model, and report its performance and error analysis (this sheet)**\n",
    "- Perform feature selection to find most salient features\n",
    "- Explore ways to deal with unbalanced data\n",
    "- Try using external ML classifies (e.g. IBM Watson)\n",
    "etc, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_data = pd.read_pickle('/Users/ijoseph/Code/Data/Gyant/final_formatting_all_obs.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = sklearn.preprocessing.LabelEncoder()\n",
    "le_fit = le.fit(formatted_data.DX)\n",
    "le_trans = le_fit.transform(formatted_data.DX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_data['DX_enc'] = le_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ijoseph/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/ijoseph/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "standard_normed = pd.DataFrame(sklearn.preprocessing.StandardScaler().fit_transform(formatted_data.drop(['DX', 'DX_enc'], axis=1)), index=formatted_data.index , columns=formatted_data.drop(['DX', 'DX_enc'], axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_normed['DX_enc'] = formatted_data.DX_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split with seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = sklearn.model_selection.train_test_split(standard_normed, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15916, 2261), (5306, 2261))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning (via CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use some form of Stochastic Gradient Descent (computes gradients on subset of observations to save time but sacrifice accuracy) for speedups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_est = sklearn.linear_model.SGDClassifier(loss='hinge', penalty ='elasticnet', verbose=2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ElasticNet** penalty. Randomized Search $\\alpha$ (overlal penalty)  from $1 \\times 10^{-8}$ to $1 \\times 10^{8}$, `l1_ratio` (relative $L_1$ vs $L_2$ peantly) from 0.1 to 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {'alpha': np.logspace(-8,8), 'l1_ratio': np.linspace(0.1,0.9)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv_svc = sklearn.model_selection.RandomizedSearchCV(estimator=svc_est, param_distributions=param_distributions, n_jobs=3, cv=3, verbose=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  30 out of  30 | elapsed:  2.3min finished\n",
      "/Users/ijoseph/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 59.88, NNZs: 898, Bias: -204.440537, T: 15916, Avg. loss: 8.699071\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 51.31, NNZs: 864, Bias: -195.900410, T: 31832, Avg. loss: 3.625062\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 48.74, NNZs: 860, Bias: -190.944191, T: 47748, Avg. loss: 3.285287\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.34, NNZs: 850, Bias: -187.498074, T: 63664, Avg. loss: 3.088124\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 46.50, NNZs: 853, Bias: -184.836332, T: 79580, Avg. loss: 2.956824\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 56.57, NNZs: 844, Bias: -172.803930, T: 15916, Avg. loss: 7.335086\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 47.06, NNZs: 819, Bias: -165.096411, T: 31832, Avg. loss: 2.900860\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.59, NNZs: 798, Bias: -160.693205, T: 47748, Avg. loss: 2.637630\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42.11, NNZs: 803, Bias: -157.496739, T: 63664, Avg. loss: 2.532757\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.87, NNZs: 788, Bias: -155.118835, T: 79580, Avg. loss: 2.427951\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.48, NNZs: 696, Bias: -233.916561, T: 15916, Avg. loss: 3.955560\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.48, NNZs: 590, Bias: -232.383398, T: 31832, Avg. loss: 1.624043\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.66, NNZs: 536, Bias: -231.449999, T: 47748, Avg. loss: 1.627520\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.11, NNZs: 489, Bias: -230.805457, T: 63664, Avg. loss: 1.641123\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.53, NNZs: 448, Bias: -230.307810, T: 79580, Avg. loss: 1.646208\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 42.11, NNZs: 755, Bias: -237.247385, T: 15916, Avg. loss: 3.900321\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.62, NNZs: 703, Bias: -234.921844, T: 31832, Avg. loss: 1.446678\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 28.33, NNZs: 687, Bias: -233.541722, T: 47748, Avg. loss: 1.442120\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.59, NNZs: 682, Bias: -232.581595, T: 63664, Avg. loss: 1.424952\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 25.62, NNZs: 658, Bias: -231.833613, T: 79580, Avg. loss: 1.430352\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.72, NNZs: 695, Bias: -236.051445, T: 15916, Avg. loss: 3.701969\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.20, NNZs: 556, Bias: -234.899339, T: 31832, Avg. loss: 1.219967\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.08, NNZs: 473, Bias: -234.230113, T: 47748, Avg. loss: 1.234614\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15.44, NNZs: 424, Bias: -233.739604, T: 63664, Avg. loss: 1.237091\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 13.81, NNZs: 384, Bias: -233.366298, T: 79580, Avg. loss: 1.237699\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 38.33, NNZs: 700, Bias: -246.009931, T: 15916, Avg. loss: 3.540989\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 25.29, NNZs: 525, Bias: -245.008342, T: 31832, Avg. loss: 0.895542\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 20.33, NNZs: 456, Bias: -244.455479, T: 47748, Avg. loss: 0.879893\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.07, NNZs: 407, Bias: -244.038119, T: 63664, Avg. loss: 0.880122\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16.62, NNZs: 354, Bias: -243.719621, T: 79580, Avg. loss: 0.863942\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 49.58, NNZs: 844, Bias: -187.663855, T: 15916, Avg. loss: 5.624994\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.84, NNZs: 776, Bias: -182.946669, T: 31832, Avg. loss: 1.967200\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.61, NNZs: 774, Bias: -180.174699, T: 47748, Avg. loss: 1.842843\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 35.11, NNZs: 761, Bias: -178.200194, T: 63664, Avg. loss: 1.774377\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34.38, NNZs: 755, Bias: -176.647256, T: 79580, Avg. loss: 1.736319\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 56.22, NNZs: 900, Bias: -201.487099, T: 15916, Avg. loss: 5.510691\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 46.79, NNZs: 884, Bias: -195.423977, T: 31832, Avg. loss: 2.141960\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.87, NNZs: 871, Bias: -191.858413, T: 47748, Avg. loss: 2.018289\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42.30, NNZs: 873, Bias: -189.377259, T: 63664, Avg. loss: 1.947707\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 41.54, NNZs: 872, Bias: -187.419906, T: 79580, Avg. loss: 1.912097\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 59.56, NNZs: 902, Bias: -193.715135, T: 15916, Avg. loss: 6.807697\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 49.78, NNZs: 899, Bias: -186.342135, T: 31832, Avg. loss: 2.731389\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 46.45, NNZs: 895, Bias: -182.079789, T: 47748, Avg. loss: 2.529830\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44.98, NNZs: 887, Bias: -179.013090, T: 63664, Avg. loss: 2.431240\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 43.71, NNZs: 884, Bias: -176.738200, T: 79580, Avg. loss: 2.335687\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 56.48, NNZs: 815, Bias: -167.690649, T: 15916, Avg. loss: 8.002337\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 44.99, NNZs: 788, Bias: -160.680773, T: 31832, Avg. loss: 2.984633\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.66, NNZs: 781, Bias: -156.709971, T: 47748, Avg. loss: 2.718015\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 38.60, NNZs: 768, Bias: -153.871022, T: 63664, Avg. loss: 2.577930\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37.38, NNZs: 777, Bias: -151.697690, T: 79580, Avg. loss: 2.507554\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 49.35, NNZs: 800, Bias: -183.202032, T: 15916, Avg. loss: 4.282903\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.15, NNZs: 793, Bias: -178.856375, T: 31832, Avg. loss: 1.327094\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 37.02, NNZs: 785, Bias: -176.357160, T: 47748, Avg. loss: 1.230538\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 35.55, NNZs: 787, Bias: -174.587274, T: 63664, Avg. loss: 1.184360\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34.61, NNZs: 786, Bias: -173.237691, T: 79580, Avg. loss: 1.156798\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.53, NNZs: 683, Bias: -233.893312, T: 15916, Avg. loss: 3.499200\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.59, NNZs: 525, Bias: -232.875355, T: 31832, Avg. loss: 0.988257\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.65, NNZs: 459, Bias: -232.282754, T: 47748, Avg. loss: 0.980876\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.25, NNZs: 413, Bias: -231.852057, T: 63664, Avg. loss: 0.992210\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.67, NNZs: 374, Bias: -231.523116, T: 79580, Avg. loss: 0.989723\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 52.68, NNZs: 808, Bias: -193.457667, T: 15916, Avg. loss: 5.923536\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 44.15, NNZs: 787, Bias: -187.097375, T: 31832, Avg. loss: 2.610003\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.17, NNZs: 791, Bias: -183.435849, T: 47748, Avg. loss: 2.447325\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 39.89, NNZs: 780, Bias: -180.807282, T: 63664, Avg. loss: 2.370037\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 39.08, NNZs: 777, Bias: -178.799720, T: 79580, Avg. loss: 2.305132\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 56.41, NNZs: 866, Bias: -192.584819, T: 15916, Avg. loss: 5.614991\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 46.71, NNZs: 862, Bias: -186.265750, T: 31832, Avg. loss: 2.173115\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.66, NNZs: 862, Bias: -182.599731, T: 47748, Avg. loss: 2.050574\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42.16, NNZs: 863, Bias: -180.007235, T: 63664, Avg. loss: 1.953594\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.94, NNZs: 857, Bias: -178.078184, T: 79580, Avg. loss: 1.887042\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 44.10, NNZs: 706, Bias: -233.919047, T: 15916, Avg. loss: 4.116127\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.81, NNZs: 645, Bias: -231.598271, T: 31832, Avg. loss: 1.153051\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.48, NNZs: 618, Bias: -230.253578, T: 47748, Avg. loss: 1.136517\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.92, NNZs: 590, Bias: -229.282637, T: 63664, Avg. loss: 1.120224\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 27.79, NNZs: 571, Bias: -228.554438, T: 79580, Avg. loss: 1.109924\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 41.88, NNZs: 757, Bias: -225.425322, T: 15916, Avg. loss: 4.317822\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 30.68, NNZs: 729, Bias: -223.051708, T: 31832, Avg. loss: 1.572784\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.09, NNZs: 720, Bias: -221.657710, T: 47748, Avg. loss: 1.563562\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.42, NNZs: 703, Bias: -220.657586, T: 63664, Avg. loss: 1.537855\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 24.37, NNZs: 688, Bias: -219.898525, T: 79580, Avg. loss: 1.521166\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 54.67, NNZs: 835, Bias: -195.634685, T: 15916, Avg. loss: 5.073169\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 44.18, NNZs: 788, Bias: -190.969483, T: 31832, Avg. loss: 1.411197\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.98, NNZs: 769, Bias: -188.190458, T: 47748, Avg. loss: 1.337339\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 39.18, NNZs: 758, Bias: -186.272387, T: 63664, Avg. loss: 1.286952\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.28, NNZs: 751, Bias: -184.753133, T: 79580, Avg. loss: 1.275246\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 43.25, NNZs: 718, Bias: -186.508266, T: 15916, Avg. loss: 3.031206\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.97, NNZs: 695, Bias: -183.291724, T: 31832, Avg. loss: 0.898830\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.29, NNZs: 692, Bias: -181.458522, T: 47748, Avg. loss: 0.857567\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 31.32, NNZs: 688, Bias: -180.108792, T: 63664, Avg. loss: 0.851966\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 30.51, NNZs: 679, Bias: -179.109057, T: 79580, Avg. loss: 0.821120\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 37.24, NNZs: 710, Bias: -236.641115, T: 15916, Avg. loss: 3.273571\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.95, NNZs: 514, Bias: -235.865567, T: 31832, Avg. loss: 0.682441\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.00, NNZs: 412, Bias: -235.426787, T: 47748, Avg. loss: 0.676537\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.55, NNZs: 344, Bias: -235.103962, T: 63664, Avg. loss: 0.668650\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.01, NNZs: 299, Bias: -234.860489, T: 79580, Avg. loss: 0.667353\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 54.48, NNZs: 871, Bias: -186.160508, T: 15916, Avg. loss: 6.033678\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 45.64, NNZs: 840, Bias: -179.912880, T: 31832, Avg. loss: 2.143458\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 42.93, NNZs: 834, Bias: -176.230321, T: 47748, Avg. loss: 1.933349\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 41.71, NNZs: 831, Bias: -173.617223, T: 63664, Avg. loss: 1.852447\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.76, NNZs: 841, Bias: -171.653371, T: 79580, Avg. loss: 1.785460\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.40, NNZs: 722, Bias: -236.148961, T: 15916, Avg. loss: 3.389742\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.52, NNZs: 550, Bias: -235.097621, T: 31832, Avg. loss: 0.991145\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.78, NNZs: 477, Bias: -234.476258, T: 47748, Avg. loss: 1.003291\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.34, NNZs: 420, Bias: -234.033110, T: 63664, Avg. loss: 1.005285\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.85, NNZs: 379, Bias: -233.696357, T: 79580, Avg. loss: 1.010421\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.53, NNZs: 670, Bias: -235.916445, T: 15916, Avg. loss: 3.325067\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.87, NNZs: 499, Bias: -234.964442, T: 31832, Avg. loss: 0.842779\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.41, NNZs: 419, Bias: -234.404485, T: 47748, Avg. loss: 0.847953\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.18, NNZs: 370, Bias: -234.001500, T: 63664, Avg. loss: 0.834423\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.88, NNZs: 329, Bias: -233.687670, T: 79580, Avg. loss: 0.826124\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 55.24, NNZs: 885, Bias: -161.647114, T: 15916, Avg. loss: 8.805373\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.84, NNZs: 852, Bias: -154.472971, T: 31832, Avg. loss: 3.198666\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.03, NNZs: 831, Bias: -150.228457, T: 47748, Avg. loss: 2.928439\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 38.11, NNZs: 831, Bias: -147.242953, T: 63664, Avg. loss: 2.761851\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36.80, NNZs: 826, Bias: -144.957617, T: 79580, Avg. loss: 2.680097\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 47.58, NNZs: 790, Bias: -217.983226, T: 15916, Avg. loss: 3.935105\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 37.75, NNZs: 778, Bias: -214.778248, T: 31832, Avg. loss: 1.124626\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.10, NNZs: 771, Bias: -212.838047, T: 47748, Avg. loss: 1.139037\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 33.68, NNZs: 765, Bias: -211.491743, T: 63664, Avg. loss: 1.091413\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 33.03, NNZs: 750, Bias: -210.428924, T: 79580, Avg. loss: 1.094884\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 51.76, NNZs: 846, Bias: -209.892735, T: 15916, Avg. loss: 5.086500\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.17, NNZs: 846, Bias: -205.389372, T: 31832, Avg. loss: 1.666523\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.51, NNZs: 841, Bias: -202.670499, T: 47748, Avg. loss: 1.551374\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 38.33, NNZs: 841, Bias: -200.752485, T: 63664, Avg. loss: 1.516884\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37.31, NNZs: 845, Bias: -199.335925, T: 79580, Avg. loss: 1.470719\n",
      "Total training time: 0.85 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   21.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='elasticnet',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=2, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=3,\n",
       "          param_distributions={'alpha': array([  1.00000e-08,   2.12095e-08,   4.49843e-08,   9.54095e-08,\n",
       "         2.02359e-07,   4.29193e-07,   9.10298e-07,   1.93070e-06,\n",
       "         4.09492e-06,   8.68511e-06,   1.84207e-05,   3.90694e-05,\n",
       "         8.28643e-05,   1.75751e-04,   3.72759e-04,   7.90604e-04,\n",
       "  ...939,\n",
       "        0.78571,  0.80204,  0.81837,  0.83469,  0.85102,  0.86735,\n",
       "        0.88367,  0.9    ])},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_rscv_svc = rscv_svc.fit(X=train.drop('DX_enc', axis=1), y=train.DX_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63112591103292282"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_rscv_svc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0035564803062231283, 'l1_ratio': 0.26326530612244903}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_rscv_svc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0035564803062231283, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.26326530612244903, learning_rate='optimal', loss='hinge',\n",
       "       max_iter=None, n_iter=None, n_iter_no_change=5, n_jobs=None,\n",
       "       penalty='elasticnet', power_t=0.5, random_state=42, shuffle=True,\n",
       "       tol=None, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_rscv_svc.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrainer = sklearn.linear_model.SGDClassifier(loss='hinge', penalty ='elasticnet', verbose=2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrainer = retrainer.set_params(**fit_rscv_svc.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ijoseph/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 59.88, NNZs: 898, Bias: -204.440537, T: 15916, Avg. loss: 8.699071\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 51.31, NNZs: 864, Bias: -195.900410, T: 31832, Avg. loss: 3.625062\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 48.74, NNZs: 860, Bias: -190.944191, T: 47748, Avg. loss: 3.285287\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.34, NNZs: 850, Bias: -187.498074, T: 63664, Avg. loss: 3.088124\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 46.50, NNZs: 853, Bias: -184.836332, T: 79580, Avg. loss: 2.956824\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 56.57, NNZs: 844, Bias: -172.803930, T: 15916, Avg. loss: 7.335086\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 47.06, NNZs: 819, Bias: -165.096411, T: 31832, Avg. loss: 2.900860\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.59, NNZs: 798, Bias: -160.693205, T: 47748, Avg. loss: 2.637630\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42.11, NNZs: 803, Bias: -157.496739, T: 63664, Avg. loss: 2.532757\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.87, NNZs: 788, Bias: -155.118835, T: 79580, Avg. loss: 2.427951\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.48, NNZs: 696, Bias: -233.916561, T: 15916, Avg. loss: 3.955560\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.48, NNZs: 590, Bias: -232.383398, T: 31832, Avg. loss: 1.624043\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.66, NNZs: 536, Bias: -231.449999, T: 47748, Avg. loss: 1.627520\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.11, NNZs: 489, Bias: -230.805457, T: 63664, Avg. loss: 1.641123\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.53, NNZs: 448, Bias: -230.307810, T: 79580, Avg. loss: 1.646208\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 42.11, NNZs: 755, Bias: -237.247385, T: 15916, Avg. loss: 3.900321\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.62, NNZs: 703, Bias: -234.921844, T: 31832, Avg. loss: 1.446678\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 28.33, NNZs: 687, Bias: -233.541722, T: 47748, Avg. loss: 1.442120\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.59, NNZs: 682, Bias: -232.581595, T: 63664, Avg. loss: 1.424952\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 25.62, NNZs: 658, Bias: -231.833613, T: 79580, Avg. loss: 1.430352\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.72, NNZs: 695, Bias: -236.051445, T: 15916, Avg. loss: 3.701969\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.20, NNZs: 556, Bias: -234.899339, T: 31832, Avg. loss: 1.219967\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.08, NNZs: 473, Bias: -234.230113, T: 47748, Avg. loss: 1.234614\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15.44, NNZs: 424, Bias: -233.739604, T: 63664, Avg. loss: 1.237091\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 13.81, NNZs: 384, Bias: -233.366298, T: 79580, Avg. loss: 1.237699\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 38.33, NNZs: 700, Bias: -246.009931, T: 15916, Avg. loss: 3.540989\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 25.29, NNZs: 525, Bias: -245.008342, T: 31832, Avg. loss: 0.895542\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 20.33, NNZs: 456, Bias: -244.455479, T: 47748, Avg. loss: 0.879893\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.07, NNZs: 407, Bias: -244.038119, T: 63664, Avg. loss: 0.880122\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16.62, NNZs: 354, Bias: -243.719621, T: 79580, Avg. loss: 0.863942\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 49.58, NNZs: 844, Bias: -187.663855, T: 15916, Avg. loss: 5.624994\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.84, NNZs: 776, Bias: -182.946669, T: 31832, Avg. loss: 1.967200\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.61, NNZs: 774, Bias: -180.174699, T: 47748, Avg. loss: 1.842843\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 35.11, NNZs: 761, Bias: -178.200194, T: 63664, Avg. loss: 1.774377\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34.38, NNZs: 755, Bias: -176.647256, T: 79580, Avg. loss: 1.736319\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 56.22, NNZs: 900, Bias: -201.487099, T: 15916, Avg. loss: 5.510691\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 46.79, NNZs: 884, Bias: -195.423977, T: 31832, Avg. loss: 2.141960\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.87, NNZs: 871, Bias: -191.858413, T: 47748, Avg. loss: 2.018289\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42.30, NNZs: 873, Bias: -189.377259, T: 63664, Avg. loss: 1.947707\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 41.54, NNZs: 872, Bias: -187.419906, T: 79580, Avg. loss: 1.912097\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 59.56, NNZs: 902, Bias: -193.715135, T: 15916, Avg. loss: 6.807697\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 49.78, NNZs: 899, Bias: -186.342135, T: 31832, Avg. loss: 2.731389\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 46.45, NNZs: 895, Bias: -182.079789, T: 47748, Avg. loss: 2.529830\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44.98, NNZs: 887, Bias: -179.013090, T: 63664, Avg. loss: 2.431240\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 43.71, NNZs: 884, Bias: -176.738200, T: 79580, Avg. loss: 2.335687\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 56.48, NNZs: 815, Bias: -167.690649, T: 15916, Avg. loss: 8.002337\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 44.99, NNZs: 788, Bias: -160.680773, T: 31832, Avg. loss: 2.984633\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.66, NNZs: 781, Bias: -156.709971, T: 47748, Avg. loss: 2.718015\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 38.60, NNZs: 768, Bias: -153.871022, T: 63664, Avg. loss: 2.577930\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37.38, NNZs: 777, Bias: -151.697690, T: 79580, Avg. loss: 2.507554\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 49.35, NNZs: 800, Bias: -183.202032, T: 15916, Avg. loss: 4.282903\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40.15, NNZs: 793, Bias: -178.856375, T: 31832, Avg. loss: 1.327094\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 37.02, NNZs: 785, Bias: -176.357160, T: 47748, Avg. loss: 1.230538\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 35.55, NNZs: 787, Bias: -174.587274, T: 63664, Avg. loss: 1.184360\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34.61, NNZs: 786, Bias: -173.237691, T: 79580, Avg. loss: 1.156798\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.53, NNZs: 683, Bias: -233.893312, T: 15916, Avg. loss: 3.499200\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.59, NNZs: 525, Bias: -232.875355, T: 31832, Avg. loss: 0.988257\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.65, NNZs: 459, Bias: -232.282754, T: 47748, Avg. loss: 0.980876\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.25, NNZs: 413, Bias: -231.852057, T: 63664, Avg. loss: 0.992210\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.67, NNZs: 374, Bias: -231.523116, T: 79580, Avg. loss: 0.989723\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 52.68, NNZs: 808, Bias: -193.457667, T: 15916, Avg. loss: 5.923536\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 44.15, NNZs: 787, Bias: -187.097375, T: 31832, Avg. loss: 2.610003\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41.17, NNZs: 791, Bias: -183.435849, T: 47748, Avg. loss: 2.447325\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 39.89, NNZs: 780, Bias: -180.807282, T: 63664, Avg. loss: 2.370037\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 39.08, NNZs: 777, Bias: -178.799720, T: 79580, Avg. loss: 2.305132\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 56.41, NNZs: 866, Bias: -192.584819, T: 15916, Avg. loss: 5.614991\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 46.71, NNZs: 862, Bias: -186.265750, T: 31832, Avg. loss: 2.173115\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.66, NNZs: 862, Bias: -182.599731, T: 47748, Avg. loss: 2.050574\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42.16, NNZs: 863, Bias: -180.007235, T: 63664, Avg. loss: 1.953594\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.94, NNZs: 857, Bias: -178.078184, T: 79580, Avg. loss: 1.887042\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 44.10, NNZs: 706, Bias: -233.919047, T: 15916, Avg. loss: 4.116127\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 33.81, NNZs: 645, Bias: -231.598271, T: 31832, Avg. loss: 1.153051\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.48, NNZs: 618, Bias: -230.253578, T: 47748, Avg. loss: 1.136517\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.92, NNZs: 590, Bias: -229.282637, T: 63664, Avg. loss: 1.120224\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 27.79, NNZs: 571, Bias: -228.554438, T: 79580, Avg. loss: 1.109924\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 41.88, NNZs: 757, Bias: -225.425322, T: 15916, Avg. loss: 4.317822\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 30.68, NNZs: 729, Bias: -223.051708, T: 31832, Avg. loss: 1.572784\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.09, NNZs: 720, Bias: -221.657710, T: 47748, Avg. loss: 1.563562\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.42, NNZs: 703, Bias: -220.657586, T: 63664, Avg. loss: 1.537855\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 24.37, NNZs: 688, Bias: -219.898525, T: 79580, Avg. loss: 1.521166\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 54.67, NNZs: 835, Bias: -195.634685, T: 15916, Avg. loss: 5.073169\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 44.18, NNZs: 788, Bias: -190.969483, T: 31832, Avg. loss: 1.411197\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.98, NNZs: 769, Bias: -188.190458, T: 47748, Avg. loss: 1.337339\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 39.18, NNZs: 758, Bias: -186.272387, T: 63664, Avg. loss: 1.286952\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.28, NNZs: 751, Bias: -184.753133, T: 79580, Avg. loss: 1.275246\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 43.25, NNZs: 718, Bias: -186.508266, T: 15916, Avg. loss: 3.031206\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 34.97, NNZs: 695, Bias: -183.291724, T: 31832, Avg. loss: 0.898830\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 32.29, NNZs: 692, Bias: -181.458522, T: 47748, Avg. loss: 0.857567\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 31.32, NNZs: 688, Bias: -180.108792, T: 63664, Avg. loss: 0.851966\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 30.51, NNZs: 679, Bias: -179.109057, T: 79580, Avg. loss: 0.821120\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 37.24, NNZs: 710, Bias: -236.641115, T: 15916, Avg. loss: 3.273571\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.95, NNZs: 514, Bias: -235.865567, T: 31832, Avg. loss: 0.682441\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.00, NNZs: 412, Bias: -235.426787, T: 47748, Avg. loss: 0.676537\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.55, NNZs: 344, Bias: -235.103962, T: 63664, Avg. loss: 0.668650\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.01, NNZs: 299, Bias: -234.860489, T: 79580, Avg. loss: 0.667353\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 54.48, NNZs: 871, Bias: -186.160508, T: 15916, Avg. loss: 6.033678\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 45.64, NNZs: 840, Bias: -179.912880, T: 31832, Avg. loss: 2.143458\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 42.93, NNZs: 834, Bias: -176.230321, T: 47748, Avg. loss: 1.933349\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 41.71, NNZs: 831, Bias: -173.617223, T: 63664, Avg. loss: 1.852447\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40.76, NNZs: 841, Bias: -171.653371, T: 79580, Avg. loss: 1.785460\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.40, NNZs: 722, Bias: -236.148961, T: 15916, Avg. loss: 3.389742\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.52, NNZs: 550, Bias: -235.097621, T: 31832, Avg. loss: 0.991145\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.78, NNZs: 477, Bias: -234.476258, T: 47748, Avg. loss: 1.003291\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.34, NNZs: 420, Bias: -234.033110, T: 63664, Avg. loss: 1.005285\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.85, NNZs: 379, Bias: -233.696357, T: 79580, Avg. loss: 1.010421\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.53, NNZs: 670, Bias: -235.916445, T: 15916, Avg. loss: 3.325067\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.87, NNZs: 499, Bias: -234.964442, T: 31832, Avg. loss: 0.842779\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.41, NNZs: 419, Bias: -234.404485, T: 47748, Avg. loss: 0.847953\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.18, NNZs: 370, Bias: -234.001500, T: 63664, Avg. loss: 0.834423\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.88, NNZs: 329, Bias: -233.687670, T: 79580, Avg. loss: 0.826124\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 55.24, NNZs: 885, Bias: -161.647114, T: 15916, Avg. loss: 8.805373\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43.84, NNZs: 852, Bias: -154.472971, T: 31832, Avg. loss: 3.198666\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.03, NNZs: 831, Bias: -150.228457, T: 47748, Avg. loss: 2.928439\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 38.11, NNZs: 831, Bias: -147.242953, T: 63664, Avg. loss: 2.761851\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36.80, NNZs: 826, Bias: -144.957617, T: 79580, Avg. loss: 2.680097\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 47.58, NNZs: 790, Bias: -217.983226, T: 15916, Avg. loss: 3.935105\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 37.75, NNZs: 778, Bias: -214.778248, T: 31832, Avg. loss: 1.124626\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.10, NNZs: 771, Bias: -212.838047, T: 47748, Avg. loss: 1.139037\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 33.68, NNZs: 765, Bias: -211.491743, T: 63664, Avg. loss: 1.091413\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 33.03, NNZs: 750, Bias: -210.428924, T: 79580, Avg. loss: 1.094884\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 51.76, NNZs: 846, Bias: -209.892735, T: 15916, Avg. loss: 5.086500\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.17, NNZs: 846, Bias: -205.389372, T: 31832, Avg. loss: 1.666523\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 39.51, NNZs: 841, Bias: -202.670499, T: 47748, Avg. loss: 1.551374\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 38.33, NNZs: 841, Bias: -200.752485, T: 63664, Avg. loss: 1.516884\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 37.31, NNZs: 845, Bias: -199.335925, T: 79580, Avg. loss: 1.470719\n",
      "Total training time: 1.24 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   21.1s finished\n"
     ]
    }
   ],
   "source": [
    "retrainer_fit = retrainer.fit(X=train.drop('DX_enc', axis=1), y=train.DX_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68296054284996233"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrainer_fit.score(X=train.drop('DX_enc', axis=1), y=train.DX_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset accuracy score. Not bad. \n",
    "> [subset accuracy](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html): the set of labels predicted for a sample must exactly match the corresponding set of labels in y_true."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
